{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "* [Pytorch Transform Documentation](http://pytorch.org/docs/torchvision/transforms.html)\n",
    "\n",
    "\n",
    "1. **torchvision.transforms.Compose:** 여러개의 tranforms을 실행합니다. \n",
    "2. **torchvision.transforms.ToTensor:** PIL.Image 또는 [0, 255] range의 Numpy array(H x W x C)를 (C x H x W)의 **[0.0, 1.0] range**를 갖은 torch.FloatTensor로 변형시킵니다. <br>여기서 포인트가 0에서 1사이의 값을 갖은 값으로 normalization이 포함되있습니다. \n",
    "3. **dataloader.DataLoader:** 사용하여 training시킬때 1개의 batch를 가져올때 shape이 **torch.Size([64, 1, 28, 28])** 이렇게 나옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST('./data', train=True, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "]), )\n",
    "\n",
    "test = MNIST('./data', train=False, download=True, transform=transforms.Compose([\n",
    "    transforms.ToTensor(), # ToTensor does min-max normalization. \n",
    "]), )\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader_args = dict(shuffle=True, batch_size=1,num_workers=1, pin_memory=True)\n",
    "train_loader = dataloader.DataLoader(train, **dataloader_args)\n",
    "test_loader = dataloader.DataLoader(test, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shagesh\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\n",
      " - Numpy Shape: (60000, 28, 28)\n",
      " - Tensor Shape: torch.Size([60000, 28, 28])\n",
      " - Transformed Shape: torch.Size([28, 60000, 28])\n",
      " - min: tensor(0.)\n",
      " - max: tensor(1.)\n",
      " - mean: tensor(0.1307)\n",
      " - std: tensor(0.3081)\n",
      " - var: tensor(0.0949)\n"
     ]
    }
   ],
   "source": [
    "train_data = train.train_data\n",
    "train_data = train.transform(train_data.numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train.train_data.size())\n",
    "print(' - Transformed Shape:', train_data.size())\n",
    "print(' - min:', torch.min(train_data))\n",
    "print(' - max:', torch.max(train_data))\n",
    "print(' - mean:', torch.mean(train_data))\n",
    "print(' - std:', torch.std(train_data))\n",
    "print(' - var:', torch.var(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_inputs, n_neurons, Wx_in, Wy_in, Y_hat_in):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.Wx = Wx_in # n_inputs X n_neurons\n",
    "        self.Wy = Wy_in # n_neurons X n_neurons\n",
    "        self.Y_hat = Y_hat_in # 1 x n_neurons\n",
    "        \n",
    "        self.Y0 = torch.randn(1, n_neurons) # 1 X n_neurons\n",
    "        \n",
    "        self.eta = 0.01 # learning rate\n",
    "        self.ceiling = 100 # maximum activity\n",
    "        self.input_size = n_inputs\n",
    "        self.neuron_size = n_neurons\n",
    "    \n",
    "    def forward(self, X1):\n",
    "#        self.Y0 = torch.ReLU(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons\n",
    "        \n",
    "        self.Y0 = torch.mm(X1, self.Wx) - torch.mm(self.Y0, self.Wy) # batch_size X n_neurons, highest activity 100\n",
    "        self.Y0[self.Y0 < 0] = 0\n",
    "        return self.Y0\n",
    "    \n",
    "    def updateY(self, Y_in):\n",
    "        self.Y0 = self.Y0 + self.eta*(Y_in - self.Y0)\n",
    "\n",
    "    def updateY_hat(self, outputs):\n",
    "        self.Y_hat += torch.mul(outputs, outputs)\n",
    "#        self.Y_hat = torch.clamp(self.Y0, -10**10, 10**10)\n",
    "        self.Y_hat[torch.isnan(self.Y_hat)] = 0\n",
    "        \n",
    "    def updateWy(self, outputs):\n",
    "        D = torch.diag(torch.diag(self.Wy))\n",
    "        self.Wy += torch.div(torch.mm(outputs.T, outputs) - torch.mul(self.Wy, torch.mm(torch.ones((self.neuron_size, 1)), torch.mul(outputs, outputs))), torch.mm(torch.ones((self.neuron_size, 1)), self.Y_hat) + 10**-30)\n",
    "        self.Wy = self.Wy - torch.diag(torch.diag(self.Wy)) + D\n",
    "        self.Wy[torch.isnan(self.Wy)] = 0\n",
    "#        self.Wy = torch.clamp(self.Wy, -10**10, 10**10)\n",
    "\n",
    "    def updateWx(self, outputs, inputs):\n",
    "        self.Wx += torch.div(torch.mm(inputs.T, outputs) - torch.mul(self.Wx, torch.mm(torch.ones((self.input_size,1)), torch.mul(outputs, outputs))), torch.mm(torch.ones((self.input_size, 1)), self.Y_hat) + 10**-30)\n",
    "        self.Wx[torch.isnan(self.Wx)] = 0\n",
    "#        self.Wx = torch.clamp(self.Wx, -10**10, 10**10)\n",
    "\n",
    "N_INPUT = 1*28*28 # number of features in input\n",
    "N_NEURONS = 1000 # number of units in layer\n",
    "\n",
    "N_INPUT_2 = 1000 # number of features in input\n",
    "N_NEURONS_2 = 10 # number of units in layer\n",
    "\n",
    "model = Model(N_INPUT, N_NEURONS, torch.randn(N_INPUT, N_NEURONS), torch.randn(N_NEURONS, N_NEURONS), torch.randn(1, N_NEURONS))\n",
    "model_2 = Model(N_INPUT_2, N_NEURONS_2, torch.randn(N_INPUT_2, N_NEURONS_2), torch.randn(N_NEURONS_2, N_NEURONS_2), torch.randn(1, N_NEURONS_2))\n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion_check = torch.nn.MSELoss()\n",
    "model.cuda() # CUDA!\n",
    "model_2.cuda() # CUDA!\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 0 [59901/60000 (100%)]\tLoss: 26656.45507800\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1):\n",
    "    output_compare = torch.zeros(10, 10)\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        model = Model(N_INPUT, N_NEURONS, model.Wx, model.Wy, model.Y_hat)\n",
    "        model_2 = Model(N_INPUT_2, N_NEURONS_2, model_2.Wx, model_2.Wy, model_2.Y_hat)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model.forward(inputs.flatten().view(-1, 1*28*28))\n",
    "        loss = criterion(outputs, model.Y0)\n",
    "        model.updateY(outputs)\n",
    "        \n",
    "        j = 0\n",
    "        while(loss > 10**-5 and j < 10**5):\n",
    "            outputs = model.forward(inputs.flatten().view(-1, 1*28*28))\n",
    "            loss = criterion(outputs, model.Y0)\n",
    "            model.updateY(outputs)\n",
    "            j += 1\n",
    "#        print(i, \"loss:\", loss)\n",
    "        \n",
    "        model.updateY_hat(outputs)\n",
    "        model.updateWx(outputs, inputs.view(-1, 1 * 28 * 28))\n",
    "        model.updateWy(outputs)        \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_2 = model_2.forward(outputs)\n",
    "        loss_2 = criterion(outputs_2, model_2.Y0)\n",
    "        model_2.updateY(outputs_2)\n",
    "        \n",
    "        j = 0\n",
    "        while(loss_2 > 10**-5 and j < 10**5):\n",
    "            outputs_2 = model_2.forward(outputs)\n",
    "            loss_2 = criterion(outputs_2, model_2.Y0)\n",
    "            model_2.updateY(outputs_2)\n",
    "            j += 1\n",
    "#        print(i, \"loss:\", loss)\n",
    "        \n",
    "        model_2.updateY_hat(outputs_2)\n",
    "        model_2.updateWx(outputs_2, outputs)\n",
    "        model_2.updateWy(outputs_2)        \n",
    "        \n",
    "        loss_check = criterion_check(outputs_2, output_compare[labels])\n",
    "        losses.append(loss_check)\n",
    "        output_compare[labels] = outputs_2\n",
    "        \n",
    "        # Display\n",
    "        if i % 100 == 1:\n",
    "            print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                i , \n",
    "                len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), \n",
    "                loss_check), \n",
    "                end='')\n",
    "            \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[221.6072, 221.7424, 222.1394, 222.1719, 222.4467, 221.7653, 224.4931,\n",
      "         224.3775, 223.6255, 223.1928]])\n",
      "2     tensor([9])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([0])\n",
      "tensor([[0.0000, 0.0000, 0.1521, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8790,\n",
      "         1.7717]])\n",
      "7     tensor([1])\n",
      "tensor([[43.1589, 42.8830, 41.2093, 41.7156, 41.1388, 41.0786, 44.2775, 41.1570,\n",
      "         42.8238, 41.3574]])\n",
      "1     tensor([6])\n",
      "tensor([[1.6456, 1.5994, 1.6772, 1.4179, 1.2542, 1.5159, 0.0000, 1.2448, 0.8341,\n",
      "         2.2525]])\n",
      "0     tensor([9])\n",
      "tensor([[1.2491, 1.5992, 1.8412, 0.8865, 1.4966, 0.7829, 0.5949, 0.0000, 1.4045,\n",
      "         3.1828]])\n",
      "0     tensor([4])\n",
      "tensor([[1424.8674, 1427.2386, 1426.8217, 1425.3429, 1427.0277, 1422.2300,\n",
      "         1420.1433, 1422.7875, 1428.4615, 1422.6000]])\n",
      "5     tensor([3])\n",
      "tensor([[0.0000, 0.4589, 0.8534, 0.3253, 0.3360, 0.3294, 0.0000, 0.0000, 0.8622,\n",
      "         1.8979]])\n",
      "7     tensor([3])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([8])\n",
      "tensor([[344.6008, 342.8985, 344.6791, 343.4974, 344.7632, 342.8159, 343.1927,\n",
      "         344.1092, 344.6377, 343.1923]])\n",
      "2     tensor([9])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([3])\n",
      "tensor([[0.6900, 0.0000, 0.4705, 0.1243, 0.4808, 0.0000, 0.0000, 0.0000, 0.5829,\n",
      "         0.0000]])\n",
      "7     tensor([8])\n",
      "tensor([[7.2033, 7.3194, 6.5331, 7.7424, 7.0537, 7.4709, 9.3442, 7.5353, 7.5786,\n",
      "         5.4927]])\n",
      "4     tensor([2])\n",
      "tensor([[11.9785, 12.5808, 12.9493, 12.2821, 12.1093, 12.1352, 14.3217, 11.2912,\n",
      "         12.1013,  9.4788]])\n",
      "1     tensor([7])\n",
      "tensor([[670.6160, 671.0806, 671.9707, 670.7239, 671.6723, 669.2142, 672.8820,\n",
      "         671.6453, 671.4716, 667.7453]])\n",
      "8     tensor([1])\n",
      "tensor([[161.3769, 162.9825, 162.9834, 161.8529, 162.4949, 161.2260, 161.3317,\n",
      "         162.8695, 162.5512, 160.6899]])\n",
      "2     tensor([2])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.2749]])\n",
      "7     tensor([4])\n",
      "tensor([[ 99.8564, 101.3717, 101.1063, 100.6352, 100.9532, 100.0513, 104.8579,\n",
      "         102.2541,  99.7819,  99.8699]])\n",
      "9     tensor([5])\n",
      "tensor([[742.1559, 743.2751, 741.0737, 741.3648, 741.8155, 739.3771, 740.6002,\n",
      "         741.7090, 740.7446, 735.8435]])\n",
      "8     tensor([3])\n",
      "tensor([[332.7089, 332.4962, 332.4811, 332.6494, 332.5048, 331.5249, 334.1747,\n",
      "         332.6444, 332.2856, 331.7851]])\n",
      "2     tensor([4])\n",
      "tensor([[1253.0811, 1252.6954, 1252.5920, 1253.0677, 1252.4391, 1249.9437,\n",
      "         1254.0453, 1253.6663, 1252.4426, 1248.9194]])\n",
      "5     tensor([6])\n",
      "tensor([[2.4254, 4.5916, 4.1131, 3.5920, 3.5636, 3.7270, 3.7986, 1.9844, 3.6988,\n",
      "         0.9307]])\n",
      "6     tensor([6])\n",
      "tensor([[10.1016, 10.4913, 11.1058, 10.3615, 10.5731, 10.4294, 12.9705, 11.9693,\n",
      "         10.9666,  8.8132]])\n",
      "1     tensor([4])\n",
      "tensor([[1378.0721, 1379.5997, 1379.0472, 1379.3092, 1379.0615, 1376.1915,\n",
      "         1383.0321, 1378.6820, 1378.5977, 1370.1223]])\n",
      "5     tensor([6])\n",
      "tensor([[106.3758, 106.9157, 106.7645, 105.9625, 107.1701, 105.9832, 105.7763,\n",
      "         104.7881, 106.3516, 106.6226]])\n",
      "9     tensor([6])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2126]])\n",
      "7     tensor([9])\n",
      "tensor([[1.5949, 2.6147, 1.5785, 1.8361, 1.7662, 1.8082, 0.3563, 0.0000, 1.3085,\n",
      "         2.8584]])\n",
      "0     tensor([8])\n",
      "tensor([[1370.1068, 1369.4053, 1368.5787, 1369.4937, 1369.2952, 1366.2627,\n",
      "         1369.2010, 1371.4569, 1368.9371, 1359.0403]])\n",
      "5     tensor([3])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.5215]])\n",
      "7     tensor([5])\n",
      "tensor([[5.8139, 5.9924, 5.7794, 6.0020, 6.0426, 5.5503, 7.8858, 5.9458, 6.2808,\n",
      "         7.4432]])\n",
      "4     tensor([3])\n",
      "tensor([[1.4735, 1.7622, 1.8722, 1.3408, 2.0232, 1.3570, 0.0000, 0.0000, 1.1649,\n",
      "         0.0000]])\n",
      "3     tensor([2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([8])\n",
      "tensor([[0.1683, 0.0000, 0.0000, 0.0000, 0.2604, 0.2242, 0.5714, 0.4498, 0.0000,\n",
      "         1.8073]])\n",
      "7     tensor([9])\n",
      "tensor([[10.8273, 10.6820, 11.1041, 10.4224, 10.9402, 10.6793, 11.2100, 10.7229,\n",
      "          9.9422,  6.4962]])\n",
      "1     tensor([3])\n",
      "tensor([[1040.4424, 1040.6237, 1040.7660, 1040.6407, 1041.5227, 1038.6040,\n",
      "         1038.8588, 1042.7688, 1041.9546, 1038.3483]])\n",
      "5     tensor([2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([0])\n",
      "tensor([[204.8267, 204.6422, 204.7175, 204.8934, 204.4527, 204.0290, 206.6205,\n",
      "         204.3234, 204.5119, 204.6281]])\n",
      "2     tensor([3])\n",
      "tensor([[ 9.6405,  8.6276,  9.0510,  9.2504,  8.7945,  9.3468, 11.0787,  7.0312,\n",
      "          7.8662,  5.3358]])\n",
      "1     tensor([7])\n",
      "tensor([[0.6257, 0.0000, 1.1908, 1.1528, 1.5163, 1.2160, 3.7968, 0.0000, 1.9969,\n",
      "         0.6258]])\n",
      "3     tensor([8])\n",
      "tensor([[2636.3464, 2637.0610, 2636.0161, 2635.4412, 2635.8833, 2628.9290,\n",
      "         2636.2522, 2635.3967, 2634.9475, 2622.5508]])\n",
      "5     tensor([4])\n",
      "tensor([[261.2623, 261.1983, 261.2884, 261.3698, 261.3743, 261.0377, 262.3920,\n",
      "         260.6081, 261.1351, 257.8979]])\n",
      "2     tensor([9])\n",
      "tensor([[3.1019, 1.8489, 1.8506, 2.7526, 3.4147, 2.3849, 0.7395, 3.6719, 2.1613,\n",
      "         3.8774]])\n",
      "0     tensor([2])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         4.2887]])\n",
      "7     tensor([8])\n",
      "tensor([[1.6842, 1.3742, 1.3039, 1.1595, 0.9217, 0.9429, 0.0000, 4.0948, 2.0111,\n",
      "         0.6492]])\n",
      "0     tensor([1])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.9834]])\n",
      "7     tensor([0])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.6621, 1.8794, 0.4495,\n",
      "         0.0000]])\n",
      "3     tensor([5])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5585]])\n",
      "7     tensor([9])\n",
      "tensor([[837.4872, 835.9289, 836.5098, 837.2088, 837.7586, 835.5760, 837.2032,\n",
      "         839.0406, 836.7016, 833.9731]])\n",
      "8     tensor([8])\n",
      "tensor([[825.6904, 827.7338, 826.4980, 825.2335, 826.4409, 822.8984, 824.2067,\n",
      "         826.9528, 827.5889, 824.7052]])\n",
      "8     tensor([3])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([4])\n",
      "tensor([[1.7346, 2.2580, 2.9249, 2.3388, 2.7479, 2.1728, 1.0734, 3.9667, 2.6759,\n",
      "         4.9467]])\n",
      "0     tensor([0])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0731, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([1])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([0])\n",
      "tensor([[977.2494, 975.9628, 975.8370, 976.7615, 975.9695, 974.2673, 976.7424,\n",
      "         977.0161, 976.2487, 971.2348]])\n",
      "5     tensor([3])\n",
      "tensor([[2.7577, 2.9966, 3.5054, 3.3806, 2.9558, 3.2967, 4.1786, 1.3427, 4.1672,\n",
      "         1.5612]])\n",
      "6     tensor([0])\n",
      "tensor([[5.3111, 5.2767, 5.7629, 5.2720, 5.7111, 5.6463, 2.4316, 3.3197, 6.6095,\n",
      "         1.5806]])\n",
      "6     tensor([4])\n",
      "tensor([[4.3928, 4.4219, 5.5934, 5.3469, 5.0397, 5.2321, 4.0521, 6.8886, 3.9924,\n",
      "         8.2945]])\n",
      "6     tensor([3])\n",
      "tensor([[4.5149, 5.7880, 5.4842, 5.1151, 5.0612, 5.1475, 3.5437, 3.1329, 6.5046,\n",
      "         4.0552]])\n",
      "6     tensor([6])\n",
      "tensor([[19.1850, 19.3562, 20.6057, 19.6210, 20.8217, 20.2848, 16.4596, 20.1490,\n",
      "         21.2725, 22.1966]])\n",
      "1     tensor([2])\n",
      "tensor([[73.1938, 74.2051, 74.3251, 74.5126, 74.7628, 74.7004, 78.9954, 75.1303,\n",
      "         75.0034, 80.5123]])\n",
      "9     tensor([3])\n",
      "tensor([[2.5495, 2.0101, 1.8005, 2.4046, 2.8127, 2.5184, 1.0857, 1.8063, 2.5566,\n",
      "         0.0000]])\n",
      "3     tensor([2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([2])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([7])\n",
      "tensor([[4.9967, 4.8341, 4.7231, 4.6075, 4.2274, 4.6909, 5.7828, 3.9433, 5.2298,\n",
      "         1.9242]])\n",
      "4     tensor([5])\n",
      "tensor([[1064.8887, 1064.3190, 1064.4027, 1064.3792, 1064.7606, 1061.8861,\n",
      "         1059.2288, 1061.5421, 1062.1643, 1053.8198]])\n",
      "5     tensor([4])\n",
      "tensor([[4.7325, 3.2861, 3.5784, 3.8162, 3.3895, 3.6541, 1.4590, 3.1613, 2.7600,\n",
      "         7.3500]])\n",
      "6     tensor([1])\n",
      "tensor([[282.5659, 281.6931, 283.3461, 282.8106, 283.5619, 282.4940, 283.1491,\n",
      "         280.9746, 283.6410, 281.6166]])\n",
      "2     tensor([1])\n",
      "tensor([[375.5159, 377.8302, 375.9500, 375.4560, 375.6811, 374.3400, 379.9497,\n",
      "         376.7564, 374.7679, 372.9063]])\n",
      "2     tensor([5])\n",
      "tensor([[0.6864, 0.0000, 0.6649, 0.2522, 0.5887, 0.1417, 1.1985, 1.0761, 0.0000,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.0000]])\n",
      "7     tensor([7])\n",
      "tensor([[5.0990, 5.2388, 5.1247, 4.8903, 4.9789, 5.0296, 4.2915, 4.3948, 4.7422,\n",
      "         3.1460]])\n",
      "6     tensor([3])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([6])\n",
      "tensor([[7.9316, 7.7728, 8.9726, 8.6474, 8.5664, 8.5868, 9.8405, 9.2016, 9.2566,\n",
      "         3.3617]])\n",
      "4     tensor([5])\n",
      "tensor([[71.1683, 71.9123, 71.1090, 70.1822, 71.0387, 70.1512, 71.3030, 71.5923,\n",
      "         71.0137, 67.9171]])\n",
      "9     tensor([4])\n",
      "tensor([[362.6220, 362.5824, 362.7049, 362.2761, 362.4847, 361.3652, 363.5195,\n",
      "         361.5708, 361.9976, 356.0180]])\n",
      "2     tensor([4])\n",
      "tensor([[1.6014, 1.4142, 1.0804, 0.9606, 1.7729, 0.9383, 2.8868, 3.7496, 1.8824,\n",
      "         0.0000]])\n",
      "3     tensor([4])\n",
      "tensor([[6.7364, 7.3624, 7.2877, 7.1747, 6.8145, 7.2716, 7.3332, 3.7082, 6.9789,\n",
      "         3.8378]])\n",
      "4     tensor([0])\n",
      "tensor([[19.4709, 19.8655, 20.1500, 19.8423, 20.5601, 19.9899, 21.3207, 20.5367,\n",
      "         19.9937, 19.6267]])\n",
      "1     tensor([1])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([1])\n",
      "tensor([[90.6799, 91.4247, 91.6179, 91.0236, 91.7316, 90.9255, 88.5575, 87.9910,\n",
      "         91.4740, 95.0342]])\n",
      "9     tensor([3])\n",
      "tensor([[153.5855, 155.4872, 154.7453, 153.5880, 153.9297, 153.3970, 155.0801,\n",
      "         153.3503, 154.1788, 153.0709]])\n",
      "2     tensor([8])\n",
      "tensor([[403.1066, 405.4033, 404.2708, 404.4422, 406.0117, 403.5687, 405.7559,\n",
      "         403.1647, 404.4276, 400.1338]])\n",
      "8     tensor([0])\n",
      "tensor([[38.6226, 39.0201, 39.2708, 38.7419, 38.9648, 38.9588, 37.2655, 39.2566,\n",
      "         39.6669, 35.0605]])\n",
      "1     tensor([7])\n",
      "tensor([[340.0579, 337.2443, 338.2686, 338.5592, 338.5504, 337.6092, 342.2910,\n",
      "         338.7719, 337.5792, 340.9087]])\n",
      "2     tensor([9])\n",
      "tensor([[806.9368, 805.9509, 807.0323, 807.1566, 807.1678, 805.3713, 804.2249,\n",
      "         808.2234, 806.8447, 805.9423]])\n",
      "8     tensor([0])\n",
      "tensor([[18.5268, 17.4976, 18.4030, 18.3084, 17.9960, 18.4217, 20.5540, 19.0126,\n",
      "         18.9109, 18.7167]])\n",
      "1     tensor([4])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([8])\n",
      "tensor([[7.5990, 6.6242, 5.9514, 6.6085, 6.2889, 6.5711, 2.4787, 4.7869, 6.3971,\n",
      "         4.3742]])\n",
      "6     tensor([4])\n",
      "tensor([[1238.9822, 1238.3716, 1239.3534, 1239.3381, 1238.9224, 1236.1309,\n",
      "         1239.3115, 1241.1333, 1239.6394, 1230.5895]])\n",
      "5     tensor([0])\n",
      "tensor([[0.3969, 1.1288, 1.3617, 0.8280, 1.8188, 0.9818, 0.3977, 0.0897, 2.2757,\n",
      "         0.6356]])\n",
      "3     tensor([5])\n",
      "tensor([[547.3784, 546.4145, 546.3066, 547.0596, 545.8000, 545.7000, 546.2206,\n",
      "         545.9979, 546.7870, 544.9457]])\n",
      "8     tensor([9])\n",
      "tensor([[3.1659, 2.7336, 2.7994, 3.2431, 3.2332, 3.3080, 0.0000, 5.0121, 2.5012,\n",
      "         4.6370]])\n",
      "6     tensor([3])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1510, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([5])\n",
      "tensor([[274.1134, 272.6674, 273.7014, 274.2206, 273.7551, 273.7566, 275.2968,\n",
      "         276.6233, 273.9960, 272.7908]])\n",
      "2     tensor([6])\n",
      "tensor([[1502.9296, 1502.9835, 1501.3939, 1501.8761, 1501.8624, 1498.2751,\n",
      "         1501.4078, 1499.0822, 1502.8175, 1494.7612]])\n",
      "5     tensor([0])\n",
      "tensor([[1921.8153, 1921.8362, 1923.7095, 1923.1012, 1922.3518, 1918.6049,\n",
      "         1924.9995, 1923.5792, 1923.5972, 1911.9568]])\n",
      "5     tensor([0])\n",
      "tensor([[1.2753, 2.9924, 2.1502, 2.0945, 2.3417, 1.7649, 2.6034, 3.2003, 1.8109,\n",
      "         2.5704]])\n",
      "0     tensor([9])\n",
      "tensor([[1076.6407, 1078.6748, 1076.8877, 1076.7418, 1077.2815, 1073.5856,\n",
      "         1075.2690, 1076.4786, 1075.9487, 1069.1980]])\n",
      "5     tensor([6])\n",
      "tensor([[42.7290, 44.2426, 44.0860, 43.6392, 43.8072, 43.4756, 44.4622, 42.2335,\n",
      "         43.6257, 47.6221]])\n",
      "1     tensor([2])\n",
      "tensor([[1466.0067, 1466.7776, 1466.4114, 1464.9244, 1466.5129, 1461.2384,\n",
      "         1464.4115, 1465.9923, 1466.2445, 1462.2648]])\n",
      "5     tensor([7])\n",
      "tensor([[524.2866, 525.0198, 523.3351, 523.1773, 523.1476, 521.9065, 524.8491,\n",
      "         523.7284, 524.3203, 519.2266]])\n",
      "8     tensor([6])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([0])\n",
      "tensor([[2.5808, 3.3925, 3.3649, 3.4128, 3.8767, 3.2469, 3.5857, 4.4503, 4.3103,\n",
      "         2.2346]])\n",
      "6     tensor([3])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3519, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([9])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([0])\n",
      "tensor([[1350.3928, 1348.8542, 1349.4642, 1349.6630, 1349.0096, 1346.2892,\n",
      "         1348.5476, 1346.8430, 1349.4156, 1342.2964]])\n",
      "5     tensor([3])\n",
      "tensor([[198.6581, 198.4982, 199.7211, 199.2193, 198.5809, 199.0005, 196.6174,\n",
      "         201.8819, 199.6613, 195.6047]])\n",
      "2     tensor([9])\n",
      "tensor([[0.4896, 0.0000, 0.3534, 0.4635, 0.9358, 0.6492, 0.0000, 2.6273, 0.8944,\n",
      "         0.0000]])\n",
      "3     tensor([7])\n",
      "tensor([[447.0250, 445.6325, 446.2398, 446.8590, 448.2937, 445.6057, 448.6297,\n",
      "         445.7865, 447.6992, 441.7559]])\n",
      "8     tensor([3])\n",
      "tensor([[1092.9020, 1092.2987, 1092.8860, 1092.2809, 1092.4281, 1089.6887,\n",
      "         1090.1890, 1093.1433, 1092.3740, 1087.7848]])\n",
      "5     tensor([3])\n",
      "tensor([[539.2405, 538.3584, 537.9206, 538.2641, 537.5170, 536.9846, 538.8510,\n",
      "         540.4350, 538.1241, 534.2884]])\n",
      "8     tensor([5])\n",
      "tensor([[398.9912, 398.6088, 398.5183, 398.9196, 398.4252, 397.7928, 401.4938,\n",
      "         398.2955, 399.3163, 399.4818]])\n",
      "8     tensor([1])\n",
      "tensor([[180.1294, 181.9551, 181.3165, 181.3245, 182.0596, 181.0705, 180.0133,\n",
      "         177.9754, 183.1431, 181.3706]])\n",
      "2     tensor([3])\n",
      "tensor([[0.7739, 0.3062, 0.0192, 0.0000, 0.0332, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([9])\n",
      "tensor([[1194.0098, 1192.8818, 1193.8593, 1193.3617, 1193.6666, 1190.3732,\n",
      "         1194.6191, 1191.4294, 1194.5043, 1189.8893]])\n",
      "5     tensor([4])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([7])\n",
      "tensor([[383.6465, 384.5305, 383.4804, 383.5531, 383.8063, 382.6429, 382.3913,\n",
      "         380.3153, 383.4387, 384.6433]])\n",
      "2     tensor([8])\n",
      "tensor([[251.8848, 251.2263, 251.2086, 251.0739, 251.2823, 250.4853, 249.2458,\n",
      "         249.0973, 252.2394, 249.6664]])\n",
      "2     tensor([4])\n",
      "tensor([[1304.6885, 1308.2266, 1305.7021, 1304.5353, 1305.9197, 1300.8737,\n",
      "         1303.4354, 1305.0432, 1305.4844, 1293.8556]])\n",
      "5     tensor([9])\n",
      "tensor([[2493.3904, 2490.9072, 2493.0649, 2492.6604, 2492.9075, 2486.8132,\n",
      "         2493.9980, 2489.6895, 2492.2800, 2481.0325]])\n",
      "5     tensor([7])\n",
      "tensor([[0.5718, 0.2600, 0.4405, 0.8367, 1.1198, 0.6186, 5.9159, 1.2657, 0.0000,\n",
      "         4.1727]])\n",
      "0     tensor([4])\n",
      "tensor([[88.5683, 88.9686, 88.6886, 88.2572, 88.4010, 88.0145, 89.4456, 86.7603,\n",
      "         89.3556, 91.1981]])\n",
      "9     tensor([7])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([7])\n",
      "tensor([[116.4778, 116.1149, 115.6990, 116.3369, 116.1540, 116.1425, 115.9174,\n",
      "         117.5127, 116.6162, 120.5944]])\n",
      "9     tensor([3])\n",
      "tensor([[2045.5526, 2046.2300, 2046.3514, 2046.0614, 2045.4298, 2040.4629,\n",
      "         2042.2806, 2045.4653, 2044.3832, 2031.9438]])\n",
      "5     tensor([2])\n",
      "tensor([[141.6933, 140.2707, 142.3608, 141.9522, 141.9673, 141.8217, 142.6020,\n",
      "         141.4643, 141.2600, 137.7559]])\n",
      "2     tensor([6])\n",
      "tensor([[1325.4642, 1330.2893, 1326.5131, 1325.6340, 1327.4572, 1322.4125,\n",
      "         1322.6125, 1326.4058, 1327.5927, 1320.4913]])\n",
      "5     tensor([3])\n",
      "tensor([[803.3061, 800.8264, 801.7007, 801.6766, 801.3810, 800.0244, 797.1809,\n",
      "         802.6621, 800.9910, 796.4099]])\n",
      "8     tensor([5])\n",
      "tensor([[2.8496, 3.2878, 2.7285, 2.6959, 2.5390, 2.5019, 0.5141, 0.9066, 2.6243,\n",
      "         1.7667]])\n",
      "0     tensor([8])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([2])\n",
      "tensor([[562.0602, 562.3157, 562.2617, 561.2866, 561.8826, 559.7632, 561.8096,\n",
      "         561.0858, 561.8013, 560.5671]])\n",
      "8     tensor([5])\n",
      "tensor([[557.5408, 555.8177, 555.6422, 556.8792, 556.5339, 555.1198, 557.4105,\n",
      "         555.7285, 556.5094, 553.4865]])\n",
      "8     tensor([3])\n",
      "tensor([[534.2736, 534.3977, 535.2878, 535.0877, 534.9658, 533.5524, 539.8303,\n",
      "         536.2064, 533.8723, 533.6451]])\n",
      "8     tensor([5])\n",
      "tensor([[0.0000, 0.9676, 0.2108, 0.0000, 0.0000, 0.0000, 2.5075, 0.0000, 0.8002,\n",
      "         0.0810]])\n",
      "7     tensor([9])\n",
      "tensor([[21.7748, 26.1063, 24.2447, 22.5425, 23.8078, 22.4652, 22.8517, 21.6047,\n",
      "         23.8371, 26.5560]])\n",
      "1     tensor([6])\n",
      "tensor([[1822.6895, 1821.8936, 1821.9800, 1821.3522, 1822.4662, 1816.8746,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1820.7280, 1820.3152, 1822.1149, 1806.5869]])\n",
      "5     tensor([2])\n",
      "tensor([[1401.5045, 1401.9192, 1402.3394, 1401.7227, 1402.0049, 1398.3060,\n",
      "         1407.0684, 1401.5771, 1402.5692, 1394.8263]])\n",
      "5     tensor([7])\n",
      "tensor([[0.0000, 1.0721, 0.8365, 0.7678, 1.2987, 0.8179, 0.5689, 0.0000, 0.6628,\n",
      "         0.5108]])\n",
      "7     tensor([9])\n",
      "tensor([[987.8229, 986.3875, 988.1763, 987.3658, 987.8166, 985.2380, 985.2549,\n",
      "         987.4812, 988.4377, 982.0417]])\n",
      "5     tensor([4])\n",
      "tensor([[874.2518, 873.2039, 873.8794, 873.9159, 874.0626, 871.7438, 870.7660,\n",
      "         872.5620, 874.1079, 869.9731]])\n",
      "5     tensor([4])\n",
      "tensor([[1255.1383, 1254.6953, 1255.4291, 1254.9259, 1255.4227, 1251.9083,\n",
      "         1257.3771, 1256.2338, 1254.3297, 1247.5862]])\n",
      "5     tensor([9])\n",
      "tensor([[1.5275, 2.9605, 2.8004, 2.8150, 3.4331, 2.8107, 3.3332, 5.1526, 1.1344,\n",
      "         5.6741]])\n",
      "6     tensor([1])\n",
      "tensor([[1206.6959, 1206.4099, 1206.9290, 1207.0623, 1207.7406, 1203.9515,\n",
      "         1206.9921, 1205.8508, 1208.2191, 1198.6097]])\n",
      "5     tensor([5])\n",
      "tensor([[267.0009, 267.6096, 267.0414, 267.0419, 266.3792, 266.4551, 268.7660,\n",
      "         267.5783, 266.4007, 265.5149]])\n",
      "2     tensor([8])\n",
      "tensor([[ 9.8836, 10.3483, 10.6526,  9.8252, 10.9995,  9.9018, 11.7481, 10.7908,\n",
      "         10.1861,  8.6212]])\n",
      "1     tensor([1])\n",
      "tensor([[1241.8380, 1241.3372, 1241.9301, 1242.0367, 1242.2344, 1238.8708,\n",
      "         1244.2462, 1244.0420, 1242.0521, 1235.2179]])\n",
      "5     tensor([5])\n",
      "tensor([[862.8735, 863.2533, 863.6546, 862.5297, 864.2177, 860.1000, 865.6049,\n",
      "         863.7761, 864.5682, 856.6425]])\n",
      "5     tensor([9])\n",
      "tensor([[1566.8496, 1565.5172, 1565.9288, 1565.8273, 1566.1055, 1561.8801,\n",
      "         1562.1996, 1565.9310, 1565.1407, 1561.5621]])\n",
      "5     tensor([6])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.6487, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([4])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([0])\n",
      "tensor([[1718.1130, 1719.3467, 1717.8683, 1718.0109, 1717.9048, 1713.7207,\n",
      "         1717.9806, 1717.6633, 1717.3326, 1710.3367]])\n",
      "5     tensor([2])\n",
      "tensor([[997.8339, 997.9760, 996.3323, 996.8869, 996.3909, 994.0037, 997.8710,\n",
      "         995.8074, 997.6005, 992.8842]])\n",
      "5     tensor([8])\n",
      "tensor([[690.1354, 688.9799, 689.8587, 690.0732, 688.5722, 688.5338, 690.9117,\n",
      "         692.8753, 690.2559, 689.4557]])\n",
      "8     tensor([6])\n",
      "tensor([[1.3032, 1.6579, 1.2126, 1.4433, 1.4040, 1.5741, 1.5581, 3.1068, 1.3095,\n",
      "         0.0000]])\n",
      "3     tensor([2])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5310]])\n",
      "7     tensor([0])\n",
      "tensor([[0.7232, 0.7946, 1.4061, 1.0478, 1.1435, 0.8553, 2.8177, 0.5082, 2.2350,\n",
      "         6.8309]])\n",
      "0     tensor([8])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1326, 0.2593, 0.3463,\n",
      "         0.0000]])\n",
      "7     tensor([1])\n",
      "tensor([[293.4894, 295.5933, 294.4529, 293.6690, 294.3021, 292.6667, 296.4199,\n",
      "         295.2939, 295.1272, 295.1286]])\n",
      "2     tensor([8])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5212, 1.9953, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([8])\n",
      "tensor([[1057.1449, 1059.6812, 1057.5315, 1056.6367, 1058.0642, 1053.8959,\n",
      "         1057.3695, 1056.8182, 1058.2125, 1051.6926]])\n",
      "5     tensor([9])\n",
      "tensor([[52.5154, 53.2020, 53.4719, 52.9057, 52.9121, 52.8145, 55.5382, 51.8716,\n",
      "         54.7676, 49.4638]])\n",
      "1     tensor([5])\n",
      "tensor([[2.8583, 2.6709, 3.0390, 3.0159, 3.1690, 2.6945, 0.3683, 3.6215, 3.2279,\n",
      "         3.2602]])\n",
      "6     tensor([9])\n",
      "tensor([[1473.3832, 1474.1635, 1473.5089, 1473.1677, 1473.4657, 1469.8087,\n",
      "         1473.5450, 1472.5667, 1473.9763, 1466.0955]])\n",
      "5     tensor([2])\n",
      "tensor([[1095.1167, 1097.4390, 1095.1534, 1094.2139, 1095.1392, 1091.1917,\n",
      "         1089.7172, 1094.4874, 1094.6997, 1088.0320]])\n",
      "5     tensor([8])\n",
      "tensor([[0.7650, 2.6585, 1.5447, 1.1186, 1.8878, 1.1877, 1.3262, 0.0000, 2.4567,\n",
      "         0.0000]])\n",
      "3     tensor([6])\n",
      "tensor([[280.5654, 281.3452, 280.6457, 280.8597, 281.1377, 279.9083, 280.8843,\n",
      "         284.3790, 281.5828, 282.8567]])\n",
      "2     tensor([7])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([4])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([2])\n",
      "tensor([[1.9142, 2.7565, 2.8065, 2.4667, 2.0765, 2.5374, 0.0000, 2.3088, 2.3438,\n",
      "         3.6725]])\n",
      "0     tensor([9])\n",
      "tensor([[652.6652, 652.9939, 652.0662, 651.9109, 652.3387, 650.5729, 649.8720,\n",
      "         652.5123, 651.9766, 653.6157]])\n",
      "8     tensor([6])\n",
      "tensor([[1178.0649, 1177.6576, 1178.6088, 1177.8342, 1178.5404, 1174.9508,\n",
      "         1179.2913, 1178.5682, 1178.6913, 1169.0486]])\n",
      "5     tensor([0])\n",
      "tensor([[2.5861, 0.9307, 2.6522, 2.5189, 2.3453, 2.5970, 4.3123, 2.2430, 2.7878,\n",
      "         0.0000]])\n",
      "3     tensor([8])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([1])\n",
      "tensor([[5.0053, 5.9740, 4.9666, 5.0162, 4.7277, 5.3128, 3.0236, 5.4944, 4.0414,\n",
      "         0.2868]])\n",
      "6     tensor([0])\n",
      "tensor([[5.9834, 6.6742, 7.9336, 7.3427, 8.2514, 7.5872, 5.3406, 7.9298, 7.0519,\n",
      "         5.7807]])\n",
      "4     tensor([9])\n",
      "tensor([[3.7098, 4.7862, 4.9094, 4.1317, 4.7452, 3.8835, 4.3428, 2.9769, 3.0313,\n",
      "         0.0000]])\n",
      "6     tensor([9])\n",
      "tensor([[11.6962, 14.7719, 13.6811, 12.3824, 13.2569, 12.4802, 12.7377, 12.1489,\n",
      "         13.5264, 14.6851]])\n",
      "1     tensor([0])\n",
      "tensor([[562.4324, 563.0551, 562.4227, 561.4368, 561.3600, 560.4628, 557.1682,\n",
      "         561.1749, 562.1736, 559.5901]])\n",
      "8     tensor([6])\n",
      "tensor([[6.9700, 6.1351, 5.8160, 6.1321, 5.7953, 5.6658, 5.0891, 5.9707, 5.1885,\n",
      "         7.2989]])\n",
      "4     tensor([3])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.5421]])\n",
      "7     tensor([9])\n",
      "tensor([[455.9855, 456.8554, 457.7597, 456.4548, 456.7745, 455.3430, 457.5322,\n",
      "         456.2830, 456.2591, 453.3980]])\n",
      "8     tensor([3])\n",
      "tensor([[1140.8671, 1140.2173, 1142.0282, 1140.6866, 1141.1752, 1137.8999,\n",
      "         1144.0286, 1140.7644, 1140.9910, 1134.6523]])\n",
      "5     tensor([8])\n",
      "tensor([[685.0372, 683.7533, 683.6584, 684.3141, 683.7389, 682.6667, 683.0962,\n",
      "         686.0422, 683.6194, 681.7977]])\n",
      "8     tensor([6])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1987, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([7])\n",
      "tensor([[347.3807, 348.1166, 348.3661, 348.1731, 347.4760, 347.5660, 350.7623,\n",
      "         347.8012, 347.5651, 341.6845]])\n",
      "2     tensor([1])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([3])\n",
      "tensor([[1829.5476, 1830.3843, 1828.6580, 1828.8887, 1828.7509, 1823.8274,\n",
      "         1833.7124, 1829.7396, 1830.1324, 1819.7720]])\n",
      "5     tensor([0])\n",
      "tensor([[1060.3212, 1060.1255, 1062.1421, 1061.1829, 1061.4565, 1058.8000,\n",
      "         1062.1732, 1063.4287, 1060.7714, 1056.1904]])\n",
      "5     tensor([5])\n",
      "tensor([[215.7928, 219.1074, 216.5393, 216.6086, 217.6364, 215.8120, 217.2160,\n",
      "         214.6369, 217.3586, 212.5938]])\n",
      "2     tensor([6])\n",
      "tensor([[0.7171, 1.6999, 1.4785, 1.0811, 1.6838, 1.2867, 0.0000, 5.1030, 2.1558,\n",
      "         2.8126]])\n",
      "0     tensor([0])\n",
      "tensor([[535.7946, 537.1205, 536.6701, 536.1804, 536.7432, 535.0781, 534.6130,\n",
      "         536.7564, 536.8777, 532.8386]])\n",
      "8     tensor([3])\n",
      "tensor([[3.7151, 3.9136, 5.0691, 4.0229, 3.6007, 3.9411, 1.9308, 0.6448, 3.4394,\n",
      "         5.9828]])\n",
      "6     tensor([9])\n",
      "tensor([[65.4348, 66.2203, 65.6236, 65.4258, 65.8972, 65.1501, 63.1509, 67.5643,\n",
      "         66.6347, 66.2761]])\n",
      "1     tensor([6])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5786, 0.0000, 0.0000,\n",
      "         0.1823]])\n",
      "7     tensor([0])\n",
      "tensor([[2.7911, 1.1062, 2.3213, 2.4562, 2.6688, 2.7476, 0.9146, 4.2925, 2.7287,\n",
      "         0.0678]])\n",
      "3     tensor([7])\n",
      "tensor([[1.8349, 1.0701, 1.4164, 1.6274, 1.5126, 1.3816, 3.3815, 2.9675, 0.4969,\n",
      "         2.9152]])\n",
      "0     tensor([2])\n",
      "tensor([[7.5583, 7.3628, 8.8877, 7.7209, 8.2769, 7.4786, 9.3905, 8.7450, 7.3306,\n",
      "         7.9492]])\n",
      "1     tensor([0])\n",
      "tensor([[2.6511, 2.2927, 3.8991, 3.1729, 3.9705, 3.0083, 4.0137, 3.5646, 2.8786,\n",
      "         2.9777]])\n",
      "6     tensor([8])\n",
      "tensor([[1560.4211, 1559.6959, 1559.6655, 1560.0836, 1560.6882, 1556.1044,\n",
      "         1560.5139, 1561.2972, 1558.7562, 1555.0394]])\n",
      "5     tensor([4])\n",
      "tensor([[4.4483, 3.4676, 2.9853, 3.6637, 3.6856, 3.5878, 4.5494, 2.4591, 3.1130,\n",
      "         0.4556]])\n",
      "6     tensor([0])\n",
      "tensor([[5.2603, 5.5515, 3.9012, 4.3082, 4.6599, 4.4083, 2.1290, 4.3616, 4.7260,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.0000]])\n",
      "6     tensor([6])\n",
      "tensor([[738.9628, 738.3132, 738.5605, 738.7712, 738.5796, 736.9965, 737.2213,\n",
      "         739.8757, 739.2451, 730.0577]])\n",
      "8     tensor([1])\n",
      "tensor([[553.0925, 551.9789, 551.5605, 552.4125, 552.8386, 551.2154, 552.1231,\n",
      "         550.8087, 551.7892, 550.6610]])\n",
      "8     tensor([6])\n",
      "tensor([[75.3707, 76.1577, 75.5128, 75.0257, 75.5722, 74.7951, 76.6834, 72.5819,\n",
      "         75.1401, 79.2345]])\n",
      "9     tensor([5])\n",
      "tensor([[273.3433, 272.7137, 272.3227, 272.4117, 272.8703, 271.5127, 273.1174,\n",
      "         272.6283, 272.5488, 273.7441]])\n",
      "2     tensor([8])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([7])\n",
      "tensor([[2.8926, 3.0569, 3.5289, 3.1177, 2.6907, 3.3340, 2.7575, 0.0000, 3.6979,\n",
      "         3.0802]])\n",
      "6     tensor([3])\n",
      "tensor([[1.7927, 3.2153, 1.7133, 1.7113, 2.0231, 1.6600, 0.4020, 0.0000, 2.1785,\n",
      "         3.6015]])\n",
      "0     tensor([3])\n",
      "tensor([[1282.2955, 1280.8984, 1280.1427, 1280.4174, 1280.0085, 1277.7178,\n",
      "         1283.6862, 1280.6794, 1278.9620, 1273.0138]])\n",
      "5     tensor([6])\n",
      "tensor([[118.1936, 117.3920, 117.6326, 117.5350, 116.8867, 117.7923, 118.3381,\n",
      "         114.4334, 116.7201, 113.8751]])\n",
      "9     tensor([6])\n",
      "tensor([[928.7327, 929.4868, 929.0782, 928.8105, 928.6989, 926.7938, 927.9949,\n",
      "         925.3245, 929.6435, 922.7647]])\n",
      "5     tensor([1])\n",
      "tensor([[1.3586, 2.2787, 0.5540, 1.0530, 1.7684, 0.8635, 2.7405, 0.3061, 0.6360,\n",
      "         0.0000]])\n",
      "3     tensor([0])\n",
      "tensor([[578.8094, 579.3280, 579.5813, 579.3191, 579.6072, 578.0609, 580.0084,\n",
      "         581.8385, 580.5858, 576.1414]])\n",
      "8     tensor([8])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.1858, 0.0000, 1.5988, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([2])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8553, 0.0000,\n",
      "         0.0000]])\n",
      "7     tensor([0])\n",
      "tensor([[0.0782, 1.2119, 0.0419, 0.5196, 0.7585, 0.8034, 3.7624, 1.1840, 1.0875,\n",
      "         0.2127]])\n",
      "3     tensor([6])\n",
      "tensor([[3.0172, 2.8372, 3.4553, 2.9525, 2.1919, 2.8051, 5.2730, 4.6342, 2.7672,\n",
      "         2.3214]])\n",
      "6     tensor([7])\n",
      "tensor([[5.4994, 6.2517, 6.3899, 6.1691, 6.3738, 6.3698, 8.2495, 3.3279, 6.9608,\n",
      "         1.7692]])\n",
      "4     tensor([2])\n",
      "tensor([[2744.8242, 2744.6121, 2744.8850, 2744.6501, 2744.3623, 2737.9534,\n",
      "         2745.5513, 2744.7568, 2744.5178, 2733.7175]])\n",
      "5     tensor([0])\n",
      "tensor([[1.8003, 0.9535, 0.9254, 0.8850, 0.6122, 0.7695, 0.1055, 1.1945, 0.0000,\n",
      "         1.9128]])\n",
      "0     tensor([9])\n",
      "tensor([[194.0341, 194.8019, 193.8557, 194.3555, 193.9111, 193.6647, 191.0052,\n",
      "         195.3874, 194.2902, 189.7332]])\n",
      "2     tensor([1])\n",
      "tensor([[1.5491, 1.7135, 1.6288, 1.3243, 1.8765, 1.2082, 2.2462, 0.5404, 3.1785,\n",
      "         2.0515]])\n",
      "3     tensor([2])\n",
      "tensor([[1346.0586, 1345.7917, 1346.3353, 1345.9102, 1345.5020, 1342.6996,\n",
      "         1344.3889, 1346.0109, 1347.2817, 1337.7676]])\n",
      "5     tensor([7])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([3])\n",
      "tensor([[751.6992, 752.1883, 750.4843, 751.0209, 750.3577, 749.0972, 751.8092,\n",
      "         750.3604, 751.0146, 745.9444]])\n",
      "8     tensor([6])\n",
      "tensor([[10.8588, 12.9466, 11.5290, 10.7092, 11.0503, 10.6951, 10.1616, 11.1261,\n",
      "         11.7812,  7.9756]])\n",
      "1     tensor([8])\n",
      "tensor([[4.4082, 2.3053, 4.6936, 4.1692, 4.1926, 4.3694, 4.6760, 3.5323, 3.8138,\n",
      "         1.2006]])\n",
      "6     tensor([5])\n",
      "tensor([[212.9822, 211.8274, 213.1191, 212.5284, 212.8657, 212.0390, 213.9432,\n",
      "         210.4584, 212.7490, 212.6543]])\n",
      "2     tensor([6])\n",
      "tensor([[1.8243, 0.4539, 1.1170, 0.9544, 0.9602, 0.9783, 2.1066, 0.3958, 1.0745,\n",
      "         0.0907]])\n",
      "3     tensor([4])\n",
      "tensor([[53.5536, 52.9308, 53.9855, 54.0150, 53.6839, 54.0829, 52.9840, 52.3369,\n",
      "         52.7912, 56.0167]])\n",
      "1     tensor([0])\n",
      "tensor([[882.0084, 880.3102, 882.2914, 882.3418, 881.3210, 880.2068, 885.0887,\n",
      "         882.4547, 882.3359, 880.4995]])\n",
      "5     tensor([7])\n",
      "tensor([[1.2041, 1.8000, 1.2656, 0.8428, 1.6370, 0.8137, 5.8512, 1.3667, 1.4251,\n",
      "         0.0000]])\n",
      "3     tensor([0])\n",
      "tensor([[2.4484, 3.4208, 2.3796, 2.8637, 3.3112, 2.9860, 0.7600, 2.6640, 1.8350,\n",
      "         2.6238]])\n",
      "0     tensor([1])\n",
      "tensor([[39.3132, 40.8157, 39.8479, 38.4546, 40.1878, 38.2603, 39.3984, 37.3150,\n",
      "         38.8512, 38.4797]])\n",
      "1     tensor([1])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([8])\n",
      "tensor([[949.0010, 947.9238, 949.0094, 948.3716, 948.7806, 946.3099, 949.5312,\n",
      "         948.2770, 949.2213, 947.3359]])\n",
      "5     tensor([0])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([2])\n",
      "tensor([[3.0556, 1.8937, 2.2233, 2.2289, 2.7204, 2.4987, 0.5528, 3.5890, 1.8273,\n",
      "         0.0000]])\n",
      "0     tensor([4])\n",
      "tensor([[985.0063, 983.8795, 984.2237, 984.2382, 984.3799, 981.7300, 986.7009,\n",
      "         983.9473, 985.8295, 981.2870]])\n",
      "5     tensor([6])\n",
      "tensor([[1.5714, 0.8074, 0.6180, 0.7700, 0.7600, 0.7940, 0.0000, 0.0000, 1.1308,\n",
      "         0.9986]])\n",
      "7     tensor([5])\n",
      "tensor([[490.3908, 488.1349, 489.9823, 489.6615, 489.8247, 488.5202, 491.6651,\n",
      "         490.8741, 488.2877, 489.0096]])\n",
      "8     tensor([8])\n",
      "tensor([[833.5438, 834.5031, 833.6737, 834.6757, 833.9836, 832.5493, 836.1351,\n",
      "         835.3711, 835.2879, 834.0388]])\n",
      "8     tensor([5])\n",
      "tensor([[3.5254, 2.1429, 2.2522, 2.5731, 2.3397, 2.6760, 0.0000, 5.9007, 2.3080,\n",
      "         0.0000]])\n",
      "0     tensor([0])\n",
      "tensor([[664.3760, 665.7859, 665.4618, 665.1124, 664.8098, 664.0064, 663.9274,\n",
      "         665.6394, 665.8752, 659.1391]])\n",
      "8     tensor([1])\n",
      "tensor([[3.8785, 5.9635, 4.8365, 4.3533, 4.7078, 4.4945, 2.2628, 4.6915, 4.8947,\n",
      "         5.3522]])\n",
      "6     tensor([4])\n",
      "tensor([[ 8.6038,  6.5343,  7.8761,  7.8093,  7.4815,  7.6974,  3.7147,  4.9029,\n",
      "          7.7862, 10.0884]])\n",
      "4     tensor([6])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.5724]])\n",
      "7     tensor([2])\n",
      "tensor([[1.1356, 0.0000, 1.2001, 0.2686, 1.0453, 0.3501, 0.1130, 0.1547, 0.4263,\n",
      "         0.0000]])\n",
      "7     tensor([4])\n",
      "tensor([[1.1447, 1.0158, 1.1995, 2.0751, 2.3226, 1.9179, 5.3673, 2.2729, 2.0897,\n",
      "         5.3304]])\n",
      "0     tensor([5])\n",
      "tensor([[0.4817, 1.8083, 0.2315, 0.8173, 1.2071, 0.6612, 0.0000, 0.0000, 1.2101,\n",
      "         5.0469]])\n",
      "0     tensor([5])\n",
      "tensor([[819.9678, 818.7176, 818.9071, 819.2054, 818.5810, 817.2377, 819.2272,\n",
      "         817.8677, 818.3953, 811.4062]])\n",
      "8     tensor([2])\n",
      "tensor([[1453.2273, 1449.9817, 1451.9346, 1452.6469, 1452.0670, 1449.4342,\n",
      "         1457.8201, 1452.8805, 1452.3542, 1448.1633]])\n",
      "5     tensor([1])\n",
      "tensor([[6.5991, 7.2147, 6.0386, 7.4270, 6.9951, 7.5582, 9.3415, 8.2637, 7.2682,\n",
      "         6.0080]])\n",
      "4     tensor([6])\n",
      "tensor([[4.2937, 2.5450, 3.9249, 3.8610, 3.5713, 3.6795, 2.4076, 2.2236, 3.8744,\n",
      "         4.2231]])\n",
      "6     tensor([7])\n",
      "tensor([[247.8509, 248.4328, 248.3600, 247.9792, 248.1747, 247.4673, 245.5794,\n",
      "         248.5095, 247.7004, 245.4196]])\n",
      "2     tensor([5])\n",
      "tensor([[1748.2661, 1748.8774, 1747.7197, 1749.0361, 1748.4326, 1744.3623,\n",
      "         1750.8505, 1746.6431, 1747.1299, 1742.2433]])\n",
      "5     tensor([5])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([6])\n",
      "tensor([[462.6738, 463.6176, 462.0190, 462.6264, 463.1294, 461.2640, 463.4026,\n",
      "         462.9305, 463.2869, 457.9548]])\n",
      "8     tensor([3])\n",
      "tensor([[3.6910, 6.0538, 3.2171, 3.4482, 3.9229, 3.4044, 3.2352, 2.8947, 3.9049,\n",
      "         0.0000]])\n",
      "6     tensor([4])\n",
      "tensor([[2.3187, 2.9975, 2.9829, 2.8728, 2.6775, 3.1122, 3.9974, 0.1455, 2.9289,\n",
      "         0.0939]])\n",
      "3     tensor([1])\n",
      "tensor([[466.1478, 464.5669, 464.8071, 465.3146, 465.0666, 464.4038, 471.3766,\n",
      "         464.0587, 465.6012, 464.3791]])\n",
      "8     tensor([5])\n",
      "tensor([[1584.2520, 1585.7885, 1586.6689, 1586.0281, 1586.3345, 1582.0155,\n",
      "         1590.8107, 1585.0138, 1586.3411, 1581.0798]])\n",
      "5     tensor([7])\n",
      "tensor([[7.5765, 8.0220, 8.0589, 8.4011, 8.5143, 8.2259, 3.8083, 6.4742, 8.9677,\n",
      "         9.2126]])\n",
      "1     tensor([4])\n",
      "tensor([[424.0935, 422.1891, 423.5398, 423.0647, 423.4325, 422.3808, 425.1674,\n",
      "         424.2669, 424.5330, 421.7130]])\n",
      "8     tensor([0])\n",
      "tensor([[259.2145, 260.5829, 260.8041, 260.8115, 261.8526, 260.1132, 261.9128,\n",
      "         258.9997, 260.5957, 261.0642]])\n",
      "2     tensor([0])\n",
      "tensor([[851.3414, 853.5153, 854.2549, 852.3728, 853.1388, 850.1377, 854.2588,\n",
      "         853.5698, 852.7277, 848.7193]])\n",
      "5     tensor([2])\n",
      "tensor([[ 9.5923, 11.3070, 10.6865, 10.3898, 10.8090,  9.9284, 13.5857, 10.7756,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10.5596, 14.2022]])\n",
      "1     tensor([5])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([8])\n",
      "tensor([[5.5615, 6.5718, 6.0631, 5.8449, 6.1381, 5.9980, 4.8591, 3.4557, 5.8495,\n",
      "         3.6203]])\n",
      "4     tensor([7])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "7     tensor([7])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 5.3538, 0.2508, 0.0000,\n",
      "         0.7076]])\n",
      "3"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fd655ef2ae5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mdistance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_compare\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'   '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misatty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;31m# request flush on the background thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[1;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    394\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#output_compare\n",
    "distance = torch.zeros(10)\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    model = Model(N_INPUT, N_NEURONS, model.Wx, model.Wy, model.Y_hat)\n",
    "    model_2 = Model(N_INPUT_2, N_NEURONS_2, model_2.Wx, model_2.Wy, model_2.Y_hat)\n",
    "    outputs = model.forward(inputs.flatten().view(-1, 1*28*28))\n",
    "    j = 0\n",
    "    while(loss > 10**-5 and j < 10**5):\n",
    "        outputs = model.forward(inputs.flatten().view(-1, 1*28*28))\n",
    "        loss = criterion(outputs, model.Y0)\n",
    "        model.updateY(outputs)\n",
    "        j += 1\n",
    "    outputs_2 = model_2.forward(outputs)\n",
    "    j = 0\n",
    "    while(loss_2 > 10**-5 and j < 10**5):\n",
    "        outputs_2 = model_2.forward(outputs)\n",
    "        loss_2 = criterion(outputs_2, model_2.Y0)\n",
    "        model_2.updateY(outputs_2)\n",
    "        j += 1\n",
    "    for j in range(10):\n",
    "        distance[j] = torch.nn.functional.mse_loss(outputs_2[0], output_compare[j])\n",
    "    print(outputs_2)\n",
    "    print(np.argmin(distance.data.numpy()), '   ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1056, 1.4258, 1.0224, 0.6046, 0.9910, 0.4719, 0.6770, 2.5024, 0.1370,\n",
      "        1.9324])\n",
      "tensor([ 8.4415,  9.9785,  8.7024,  9.5090,  9.8807,  9.3170,  9.3587, 11.3190,\n",
      "         9.2123, 12.4195])\n",
      "tensor([138.4350, 139.5254, 139.6285, 139.8736, 139.5881, 139.2961, 139.9133,\n",
      "        141.2150, 140.4979, 138.3175])\n",
      "tensor([0.7357, 0.8298, 0.6720, 0.9445, 0.3645, 1.0492, 1.7568, 1.2148, 1.5874,\n",
      "        0.0000])\n",
      "tensor([4.6491, 5.2774, 5.9314, 5.7881, 5.7662, 5.3731, 8.3054, 4.5594, 5.6160,\n",
      "        4.6641])\n",
      "tensor([1051.2051, 1050.9301, 1051.2333, 1050.3193, 1050.9233, 1047.7910,\n",
      "        1050.7106, 1048.4510, 1051.0040, 1041.0159])\n",
      "tensor([4.8288, 4.9329, 5.5526, 4.4327, 4.5293, 4.4868, 1.4796, 3.5288, 3.2972,\n",
      "        4.4954])\n",
      "tensor([0.0000, 0.8325, 0.0000, 0.0000, 0.1031, 0.0000, 0.5006, 0.0000, 0.0000,\n",
      "        0.8513])\n",
      "tensor([628.5461, 627.4235, 627.2217, 627.2308, 627.9433, 625.0311, 627.4104,\n",
      "        629.0347, 628.6405, 623.9290])\n",
      "tensor([121.0107, 121.3654, 121.6761, 121.7563, 121.6743, 121.3467, 121.9798,\n",
      "        124.5452, 122.5023, 119.9381])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(output_compare[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20a971a2ac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(model_2.Wy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dd8bf294a8>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 3D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b68a9f7440ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-e36c11b7e0cb>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X1)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#        self.Y0 = torch.ReLU(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# batch_size X n_neurons, highest activity 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: matrices expected, got 3D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747"
     ]
    }
   ],
   "source": [
    "evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor())).cuda()\n",
    "evaluate_y = Variable(test_loader.dataset.test_labels).cuda()\n",
    "\n",
    "\n",
    "output = model(evaluate_x)\n",
    "pred = output.data.max(1)[1]\n",
    "d = pred.eq(evaluate_y.data).cpu().float()\n",
    "accuracy = d.sum()/d.size()[0]\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
