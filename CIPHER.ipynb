{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c06ccbcf90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "#        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#        self.pool = nn.MaxPool2d(2, 2)\n",
    "#        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(3 * 32 * 32, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "#        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#        x = x.view(-1, 3 * 32 * 32)\n",
    "        x = F.relu(self.fc2(self.fc1(x)))\n",
    "#        x = self.pool(F.relu(self.conv1(x)))\n",
    "#        x = self.pool(F.relu(self.conv2(x)))\n",
    "#        x = F.relu(self.fc1(x))\n",
    "#        x = F.relu(self.fc2(x))\n",
    "#        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNN(nn.Module):\n",
    "    def __init__(self, n_inputs, n_neurons, Wx_in, Wy_in, Y_hat_in):\n",
    "        super(BasicRNN, self).__init__()\n",
    "        \n",
    "        self.Wx = Wx_in # n_inputs X n_neurons\n",
    "        self.Wy = Wy_in # n_neurons X n_neurons\n",
    "        self.Y_hat = Y_hat_in # 1 x n_neurons\n",
    "        \n",
    "        self.Y0 = torch.randn(1, n_neurons) # 1 X n_neurons\n",
    "        \n",
    "        self.eta = 0.01 # learning rate\n",
    "        self.ceiling = 100 # maximum activity\n",
    "        self.input_size = n_inputs\n",
    "        self.neuron_size = n_neurons\n",
    "    \n",
    "    def forward(self, X1):\n",
    "#        self.Y0 = torch.ReLU(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons\n",
    "        \n",
    "        self.Y0 = torch.mm(X1, self.Wx) - torch.mm(self.Y0, self.Wy) # batch_size X n_neurons, highest activity 100\n",
    "        self.Y0[self.Y0 < 0] = 0\n",
    "        return self.Y0\n",
    "    \n",
    "    def updateY(self, Y_in):\n",
    "        self.Y0 = self.Y0 + self.eta*(Y_in - self.Y0)\n",
    "\n",
    "    def updateY_hat(self, outputs):\n",
    "        self.Y_hat += torch.mul(outputs, outputs)\n",
    "#        self.Y_hat = torch.clamp(self.Y0, -10**10, 10**10)\n",
    "        self.Y_hat[torch.isnan(self.Y_hat)] = 0\n",
    "        \n",
    "    def updateWy(self, outputs):\n",
    "        D = torch.diag(torch.diag(self.Wy))\n",
    "        self.Wy += torch.div(torch.mm(outputs.T, outputs) - torch.mul(self.Wy, torch.mm(torch.ones((self.neuron_size, 1)), torch.mul(outputs, outputs))), torch.mm(torch.ones((self.neuron_size, 1)), self.Y_hat) + 10**-30)\n",
    "        self.Wy = self.Wy - torch.diag(torch.diag(self.Wy)) + D\n",
    "        self.Wy[torch.isnan(self.Wy)] = 0\n",
    "#        self.Wy = torch.clamp(self.Wy, -10**10, 10**10)\n",
    "\n",
    "    def updateWx(self, outputs, inputs):\n",
    "        self.Wx += torch.div(torch.mm(inputs.T, outputs) - torch.mul(self.Wx, torch.mm(torch.ones((self.input_size,1)), torch.mul(outputs, outputs))), torch.mm(torch.ones((self.input_size, 1)), self.Y_hat) + 10**-30)\n",
    "        self.Wx[torch.isnan(self.Wx)] = 0\n",
    "#        self.Wx = torch.clamp(self.Wx, -10**10, 10**10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 1*28*28 # number of features in input\n",
    "N_NEURONS = 400 # number of units in layer\n",
    "\n",
    "N_INPUT_2 = 400 # number of features in input\n",
    "N_NEURONS_2 = 10 # number of units in layer\n",
    "\n",
    "#X0_batch = torch.randn(1, N_INPUT) #t=0 => 4 X 3\n",
    "\n",
    "#X1_batch = torch.tensor([[9,8,7,6,5], [0,0,0,0,0], \n",
    "#                         [6,5,4,3,2], [3,2,1,0,9]],\n",
    "#                        dtype = torch.float) #t=1 => 4 X 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instance\n",
    "model = BasicRNN(N_INPUT, N_NEURONS, torch.randn(N_INPUT, N_NEURONS), torch.randn(N_NEURONS, N_NEURONS), torch.randn(1, N_NEURONS))\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "inputs, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.updateY_hat(outputs)\n",
    "model.updateWx(outputs, inputs.view(-1, 3 * 32 * 32))\n",
    "model.updateWy(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 4.2458e+01, 0.0000e+00, 2.0064e+03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3320e-02, 2.3510e-02,\n",
      "         0.0000e+00, 1.1724e+02, 0.0000e+00, 6.8054e+01, 1.2884e-02, 0.0000e+00,\n",
      "         0.0000e+00, 3.1196e+03, 0.0000e+00, 3.9518e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.6536e+00, 0.0000e+00, 0.0000e+00, 1.0439e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4159e-02, 0.0000e+00, 2.4043e+04, 1.3675e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.5682e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5606e-02, 5.4868e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2593e+04, 0.0000e+00,\n",
      "         9.4821e+03, 1.1347e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2866e+04, 1.7902e+01, 2.3425e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5150e-02, 0.0000e+00, 1.0445e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1960e-02, 3.3286e+05, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.5696e-02, 0.0000e+00, 0.0000e+00, 2.1271e+03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4276e+04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.6749e-03, 9.1186e-03, 0.0000e+00]])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 4.2458e+01, 0.0000e+00, 2.0064e+03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3320e-02, 2.3510e-02,\n",
      "         0.0000e+00, 1.1724e+02, 0.0000e+00, 6.8054e+01, 1.2884e-02, 0.0000e+00,\n",
      "         0.0000e+00, 3.1196e+03, 0.0000e+00, 3.9518e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.6536e+00, 0.0000e+00, 0.0000e+00, 1.0439e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4159e-02, 0.0000e+00, 2.4043e+04, 1.3675e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.5682e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5606e-02, 5.4868e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2593e+04, 0.0000e+00,\n",
      "         9.4821e+03, 1.1347e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2866e+04, 1.7902e+01, 2.3425e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5150e-02, 0.0000e+00, 1.0445e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1960e-02, 3.3286e+05, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.5696e-02, 0.0000e+00, 0.0000e+00, 2.1271e+03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4276e+04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.6749e-03, 9.1186e-03, 0.0000e+00]])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "outputs = model.forward(inputs.flatten().view(-1, 3*32*32))\n",
    "print(model.Y0)\n",
    "print(outputs)\n",
    "loss = criterion(outputs, model.Y0)\n",
    "print(loss)\n",
    "model.updateY(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while(loss > 10**-5 and i < 10**5):\n",
    "    outputs = model.forward(inputs.flatten().view(-1, 3*32*32))\n",
    "    loss = criterion(outputs, model.Y0)\n",
    "    model.updateY(outputs)\n",
    "    i += 1\n",
    "    if i%20000 == 19999:\n",
    "        print(i+1, \"loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 4.2458e+01, 0.0000e+00, 2.0064e+03, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3320e-02, 2.3510e-02,\n",
      "         0.0000e+00, 1.1724e+02, 0.0000e+00, 6.8054e+01, 1.2884e-02, 0.0000e+00,\n",
      "         0.0000e+00, 3.1196e+03, 0.0000e+00, 3.9518e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.6536e+00, 0.0000e+00, 0.0000e+00, 1.0439e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.4159e-02, 0.0000e+00, 2.4043e+04, 1.3675e-02,\n",
      "         0.0000e+00, 0.0000e+00, 3.5682e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5606e-02, 5.4868e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2593e+04, 0.0000e+00,\n",
      "         9.4821e+03, 1.1347e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2866e+04, 1.7902e+01, 2.3425e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.5150e-02, 0.0000e+00, 1.0445e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.1960e-02, 3.3286e+05, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 8.5696e-02, 0.0000e+00, 0.0000e+00, 2.1271e+03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4276e+04, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 4.6749e-03, 9.1186e-03, 0.0000e+00]])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "          74689.5391,  34386.5664,      0.0000,      0.0000,  79609.4453,\n",
      "              0.0000,  72953.7188,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,  21809.1562,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,  23667.5312,      0.0000,      0.0000,\n",
      "          59126.1602,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,  50561.1562, 147375.4375,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "          71240.9844,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "          34513.1758,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,  89570.2812,      0.0000,\n",
      "          82216.4062,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "          67588.8516,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,   9434.5127,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000,      0.0000,      0.0000,      0.0000,\n",
      "              0.0000,      0.0000, 170943.5469,  88671.8438,      0.0000]])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer_1 = optim.SGD(net.fc1.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer_2 = optim.SGD(net.fc2.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicRNN(N_INPUT, N_NEURONS, torch.randn(N_INPUT, N_NEURONS), torch.ones(N_NEURONS, N_NEURONS)*1000, torch.randn(1, N_NEURONS))\n",
    "model_2 = BasicRNN(N_INPUT_2, N_NEURONS_2, torch.randn(N_INPUT_2, N_NEURONS_2), torch.ones(N_NEURONS_2, N_NEURONS_2)*1000, torch.randn(1, N_NEURONS_2))\n",
    "criterion = torch.nn.MSELoss()\n",
    "criterion_check = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_compare = torch.zeros(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10000] loss: 49189232.000\n",
      "[1, 20000] loss: 2775188.000\n",
      "[1, 30000] loss: 2792443.250\n",
      "[1, 40000] loss: 2809801.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        model = BasicRNN(N_INPUT, N_NEURONS, model.Wx, model.Wy, model.Y_hat)\n",
    "        model_2 = BasicRNN(N_INPUT_2, N_NEURONS_2, model_2.Wx, model_2.Wy, model_2.Y_hat)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model.forward(inputs.flatten().view(-1, 1*28*28))\n",
    "        loss = criterion(outputs, model.Y0)\n",
    "        model.updateY(outputs)\n",
    "        \n",
    "        j = 0\n",
    "        while(loss > 10**-5 and j < 10**5):\n",
    "            outputs = model.forward(inputs.flatten().view(-1, 1*28*28))\n",
    "            loss = criterion(outputs, model.Y0)\n",
    "            model.updateY(outputs)\n",
    "            j += 1\n",
    "#        print(i, \"loss:\", loss)\n",
    "        \n",
    "        model.updateY_hat(outputs)\n",
    "        model.updateWx(outputs, inputs.view(-1, 1 * 28 * 28))\n",
    "        model.updateWy(outputs)        \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_2 = model_2.forward(outputs)\n",
    "        loss_2 = criterion(outputs_2, model_2.Y0)\n",
    "        model_2.updateY(outputs_2)\n",
    "        \n",
    "        j = 0\n",
    "        while(loss_2 > 10**-5 and j < 10**5):\n",
    "            outputs_2 = model_2.forward(outputs)\n",
    "            loss_2 = criterion(outputs_2, model_2.Y0)\n",
    "            model_2.updateY(outputs_2)\n",
    "            j += 1\n",
    "#        print(i, \"loss:\", loss)\n",
    "        \n",
    "        model_2.updateY_hat(outputs_2)\n",
    "        model_2.updateWx(outputs_2, outputs)\n",
    "        model_2.updateWy(outputs_2)        \n",
    "\n",
    "        \n",
    "        # print statistics\n",
    "        loss_check = criterion_check(outputs_2, output_compare[labels])\n",
    "        running_loss += loss_check\n",
    "        output_compare[labels] = outputs_2\n",
    "        if i % 10000 == 9999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:      3\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 4D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-6e53c5807822>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-711e61f8bd72>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X1)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#        self.Y0 = torch.ReLU(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# batch_size X n_neurons, highest activity 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: matrices expected, got 4D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747"
     ]
    }
   ],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-57678022f418>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n\u001b[1;32m----> 4\u001b[1;33m                               for j in range(1)))\n\u001b[0m",
      "\u001b[1;32m<ipython-input-41-57678022f418>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n\u001b[1;32m----> 4\u001b[1;33m                               for j in range(1)))\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 4D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-5ef0030d31c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-711e61f8bd72>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X1)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#        self.Y0 = torch.ReLU(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# batch_size X n_neurons, highest activity 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: matrices expected, got 4D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 4D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-dd0922d071e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-711e61f8bd72>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X1)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#        self.Y0 = torch.ReLU(torch.mm(X0, self.Wx) + self.b) # batch_size X n_neurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# batch_size X n_neurons, highest activity 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: matrices expected, got 4D, 2D tensors at C:\\w\\1\\s\\tmp_conda_3.7_055457\\conda\\conda-bld\\pytorch_1565416617654\\work\\aten\\src\\TH/generic/THTensorMath.cpp:747"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(1):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 10])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(inputs.view(-1, 3 * 32 * 32).T, outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
